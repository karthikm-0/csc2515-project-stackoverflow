{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_QA_Pairs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPK5j41NPFLrxEiMU0cTKB4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f15b67bb3aba45be90f5858b61931e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_29b6f940a2a54518bb93de5eb376666c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6dd168e309d6492a87e2edd1d6241628",
              "IPY_MODEL_8743aada12bb4aaf9bc7aadb987533c4"
            ]
          }
        },
        "29b6f940a2a54518bb93de5eb376666c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6dd168e309d6492a87e2edd1d6241628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d30420def9f7450294ef4e0893d7a580",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b771220f6484226934add24d046de2b"
          }
        },
        "8743aada12bb4aaf9bc7aadb987533c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cbbca0828fc141af9daba46cfa7096b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 773kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c59b1f3c2364a47b644d61d691a266a"
          }
        },
        "d30420def9f7450294ef4e0893d7a580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b771220f6484226934add24d046de2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbbca0828fc141af9daba46cfa7096b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c59b1f3c2364a47b644d61d691a266a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikm-0/csc2515-project-stackoverflow/blob/main/BERT_QA_Pairs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Crv_c9fIdqF",
        "outputId": "9c2ba8c2-6feb-4faa-9566-c1bcf324fe66"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4MB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 30.3MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 39.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=9740bd3af806637f355be3ab8d6cb3e009b957c9e691ab1bf8ec4ee704b59f76\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRHOJCNxJngl",
        "outputId": "f307815f-f659-441d-8c45-71e9ad028da7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_folder = \"./drive/My Drive/csc2515-project/\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyBnY5ORJpP0",
        "outputId": "0b03982b-8e2a-43da-d4d8-68746b5433a2"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "questions_answers = pd.read_csv(os.path.join(project_folder, \"questions_answers.csv\"))\n",
        "\n",
        "#questions_answers_test = questions_answers.sample(frac=0.2)\n",
        "\n",
        "print(questions_answers.head(5).to_string())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0  QId   QAskerId         QCreationDate QClosedDate  QScore                              QTitle                                                                                                                                                                                                                                                                  QBody     Id  OwnerUserId          CreationDate  ParentId  Score                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Body\n",
            "0           0  180  2089740.0  2008-08-01T18:42:19Z         NaN      53  Function for creating color wheels  <p>This is something I've pseudo-solved many times and never quite found a solution. That's stuck with me. The problem is to come up with a way to generate <code>N</code> colors, that are as distinguishable as possible where <code>N</code> is a parameter.</p>\\n    199         50.0  2008-08-01T19:36:46Z       180      1  <p>I've read somewhere the human eye can't distinguish between less than 4 values apart. so This is something to keep in mind. The following algorithm does not compensate for this.</p>\\r\\n\\r\\n<p>I'm not sure this is exactly what you want, but this is one way to randomly generate non-repeating color values:</p>\\r\\n\\r\\n<p>(beware, inconsistent pseudo-code ahead)</p>\\r\\n\\r\\n<pre><code>//colors entered as 0-255 [R, G, B]<br>colors = []; //holds final colors to be used<br>rand = new Random();<br><br>//assumes n is less than 16,777,216<br>randomGen(int n){<br>   while (len(colors) &lt; n){<br>      //generate a random number between 0,255 for each color<br>      newRed = rand.next(256);<br>      newGreen = rand.next(256);<br>      newBlue = rand.next(256);<br>      temp = [newRed, newGreen, newBlue];<br>      //only adds new colors to the array<br>      if temp not in colors {<br>         colors.append(temp);<br>      }<br>   }<br>}<br></code></pre>\\r\\n\\r\\n<p>One way you could optimize this for better visibility would be to compare the distance between each new color and all the colors in the array:</p>\\r\\n\\r\\n<pre><code>for item in color{<br>   itemSq = (item[0]^2 + item[1]^2 + item[2]^2])^(.5);<br>   tempSq = (temp[0]^2 + temp[1]^2 + temp[2]^2])^(.5);<br>   dist = itemSq - tempSq;<br>   dist = abs(dist);<br>}<br>//NUMBER can be your chosen distance apart.<br>if dist &lt; NUMBER and temp not in colors {<br>   colors.append(temp);<br>}<br></code></pre>\\r\\n\\r\\n<p>But this approach would significantly slow down your algorithm.</p>\\r\\n\\r\\n<p>Another way would be to scrap the randomness and systematically go through every 4 values and add a color to an array in the above example.</p>\n",
            "1           1  180  2089740.0  2008-08-01T18:42:19Z         NaN      53  Function for creating color wheels  <p>This is something I've pseudo-solved many times and never quite found a solution. That's stuck with me. The problem is to come up with a way to generate <code>N</code> colors, that are as distinguishable as possible where <code>N</code> is a parameter.</p>\\n    529         86.0  2008-08-02T18:16:07Z       180      3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <p>Isn't it also a factor which order you set up the colors?</p>\\r\\n\\r\\n<p>Like if you use Dillie-Os idea you need to mix the colors as much as possible. \\r\\n0 64 128 256 is from one to the next. but 0 256 64 128 in a wheel would be more \"apart\"</p>\\r\\n\\r\\n<p>Does this make sense?</p>\n",
            "2           2  180  2089740.0  2008-08-01T18:42:19Z         NaN      53  Function for creating color wheels  <p>This is something I've pseudo-solved many times and never quite found a solution. That's stuck with me. The problem is to come up with a way to generate <code>N</code> colors, that are as distinguishable as possible where <code>N</code> is a parameter.</p>\\n    539        157.0  2008-08-02T19:03:52Z       180     21                                                                                                                                                                                                                                                                                                                                                                                                      <p>My first thought on this is \"how generate N vectors in a space that maximize distance from each other.\" You can see that the RGB (or any other scale you use that forms a basis in color space) are just vectors. Take a look at <a href=\"http://mathworld.wolfram.com/topics/RandomPointPicking.html\">Random Point Picking</a>. Hope this is a good start for you! Once you have a set of vectors that are maximized a part, you can save them in a hash table or something for later, and just perform random rotations on them to get all the colors you desire that are maximally apart from each other!</p>\\n\\n<p><strong>Edit:</strong> Thinking about this problem more, it would be better to map the colors in a linear manor, possibly (0,0,0) --> (255,255,255) lexicographically, and then distribute them evenly. I really don't know how well this will work, but it should since, lets say:</p>\\n\\n<p>n = 10\\nwe know we have 16777216 colors (256^3). We can use <a href=\"http://stackoverflow.com/questions/561/using-combinations-of-sets-as-test-data#794\">buckles algorithm 515</a> to find the lexicographically indexed color.<img src=\"http://i.stack.imgur.com/gEuCs.gif\" alt=\"\\frac {\\binom {256^3} {3}} {n} * i\">. You'll probably have to edit the algorithm to avoid overflow and probably add some minor speed improvements.</p>\\n\n",
            "3           3  180  2089740.0  2008-08-01T18:42:19Z         NaN      53  Function for creating color wheels  <p>This is something I've pseudo-solved many times and never quite found a solution. That's stuck with me. The problem is to come up with a way to generate <code>N</code> colors, that are as distinguishable as possible where <code>N</code> is a parameter.</p>\\n  59760       5845.0  2008-09-12T19:00:13Z       180     17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     <p>It would be best to find colors maximally distant in a \"perceptually uniform\" colorspace, e.g. CIELAB (using Euclidean distance between L*, a*, b* coordinates as your distance metric) and then converting to the colorspace of your choice.  Perceptual uniformity is achieved by tweaking the colorspace to approximate the non-linearities in the human visual system.</p>\\n\n",
            "4           4  180  2089740.0  2008-08-01T18:42:19Z         NaN      53  Function for creating color wheels  <p>This is something I've pseudo-solved many times and never quite found a solution. That's stuck with me. The problem is to come up with a way to generate <code>N</code> colors, that are as distinguishable as possible where <code>N</code> is a parameter.</p>\\n  93908      16632.0  2008-09-18T16:01:24Z       180      7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <p>Some related resources:</p>\\n\\n<p><a href=\"http://colorbrewer.org\">ColorBrewer</a> - Sets of colours designed to be maximally distinguishable for use on maps.</p>\\n\\n<p><a href=\"http://epub.wu-wien.ac.at/dyn/openURL?id=oai:epub.wu-wien.ac.at:epub-wu-01_c87\">Escaping RGBland: Selecting Colors for Statistical Graphics</a> - A technical report describing a set of algorithms for generating good (i.e. maximally distinguishable) colour sets in the hcl colour space.</p>\\n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG_h8oQ6J0H8"
      },
      "source": [
        "# Perform tokenization as BERT needs it in a specific format\n",
        "def tokenize(data, type, seq_length=128):\n",
        "  from transformers import BertTokenizer\n",
        "  tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "  questions_input_ids_list = []\n",
        "  questions_attention_masks_list = []\n",
        "  answers_input_ids_list = []\n",
        "  answers_attention_masks_list = []\n",
        "  scores_list = []\n",
        "\n",
        "  for (idx, row) in data.iterrows():\n",
        "      tokenize = tokenizer([row.QBody, row.Body], max_length=seq_length, padding='max_length', truncation=True) )\n",
        "      tokenize_q = tokenizer(row.QBody, max_length=seq_length, padding='max_length', truncation=True)\n",
        "      tokenize_a = tokenize_q = tokenizer(row.Body, max_length=seq_length, padding='max_length', truncation=True)\n",
        "\n",
        "      questions_input_ids_list.append(tokenize_q['input_ids'])\n",
        "      questions_attention_masks_list.append(tokenize_q['attention_mask'])\n",
        "\n",
        "      answers_input_ids_list.append(tokenize_a['input_ids'])\n",
        "      answers_attention_masks_list.append(tokenize_a['attention_mask'])\n",
        "\n",
        "      if type == 'train':\n",
        "        scores_list.append(row.Score)\n",
        "\n",
        "  # TFBertForSequenceClassification requires Numpy arrays\n",
        "  questions_input_ids_list = np.asarray(questions_input_ids_list)\n",
        "  questions_attention_masks_list = np.array(questions_attention_masks_list)\n",
        "\n",
        "  answers_input_ids_list = np.asarray(answers_input_ids_list)\n",
        "  answers_attention_masks_list = np.array(answers_attention_masks_list)\n",
        "\n",
        "  scores_list = np.array(scores_list)\n",
        "\n",
        "  return questions_input_ids_list, questions_attention_masks_list, answers_input_ids_list, answers_attention_masks_list, scores_list"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "f15b67bb3aba45be90f5858b61931e28",
            "29b6f940a2a54518bb93de5eb376666c",
            "6dd168e309d6492a87e2edd1d6241628",
            "8743aada12bb4aaf9bc7aadb987533c4",
            "d30420def9f7450294ef4e0893d7a580",
            "4b771220f6484226934add24d046de2b",
            "cbbca0828fc141af9daba46cfa7096b4",
            "6c59b1f3c2364a47b644d61d691a266a"
          ]
        },
        "id": "4EYk3yUHMEh9",
        "outputId": "9799bb40-5079-4d81-9e54-815b6ee4c2ca"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Keep test for after we train the model and use training data only for train and val\n",
        "questions_answers_train, questions_answers_test, = train_test_split(questions_answers, test_size=0.2)\n",
        "print(questions_answers_train.shape)\n",
        "\n",
        "q_input_ids, q_attention_masks, a_input_ids, a_attention_masks, scores = tokenize(questions_answers_train, type='train')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(96348, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f15b67bb3aba45be90f5858b61931e28",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sL7_IUZNZOD"
      },
      "source": [
        "# Save the tokens for future use\n",
        "import pickle\n",
        "\n",
        "pickle_q_inp_path = os.path.join(project_folder, \"BERT/tokenized/bert_inp_q.pkl\")\n",
        "pickle_q_mask_path = os.path.join(project_folder, \"BERT/tokenized/bert_mask_q.pkl\")\n",
        "\n",
        "pickle_a_inp_path = os.path.join(project_folder, \"BERT/tokenized/bert_inp_a.pkl\")\n",
        "pickle_a_mask_path = os.path.join(project_folder, \"BERT/tokenized/bert_mask_a.pkl\")\n",
        "\n",
        "pickle_score_path = os.path.join(project_folder, \"BERT/tokenized/bert_scores.pkl\")\n",
        "\n",
        "pickle.dump((q_input_ids),open(pickle_q_inp_path,'wb'))\n",
        "pickle.dump((q_attention_masks),open(pickle_q_mask_path,'wb'))\n",
        "\n",
        "pickle.dump((a_input_ids),open(pickle_a_inp_path,'wb'))\n",
        "pickle.dump((a_attention_masks),open(pickle_a_mask_path,'wb'))\n",
        "\n",
        "pickle.dump((scores),open(pickle_score_path,'wb'))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXOtL5xGU8sa",
        "outputId": "21be1c46-5dbd-43e0-b03e-f3cc504e901c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_q_input_ids, val_q_input_ids, train_q_masks, val_q_masks, train_a_input_ids, val_a_input_ids, train_a_masks, val_a_masks, train_scores, val_scores = train_test_split(q_input_ids, q_attention_masks, a_input_ids, a_attention_masks, scores, test_size=0.2)\n",
        "\n",
        "\n",
        "print(train_q_input_ids.shape, val_q_input_ids.shape, train_q_masks.shape, val_q_masks.shape, \n",
        "      train_a_input_ids.shape, val_a_input_ids.shape, train_a_masks.shape, val_a_masks.shape,\n",
        "      train_scores.shape, val_scores.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(77078, 128) (19270, 128) (77078, 128) (19270, 128) (77078, 128) (19270, 128) (77078, 128) (19270, 128) (77078,) (19270,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpKEFQeNXGEi",
        "outputId": "73813dc0-134f-459e-b9ab-4fa6386c84fc"
      },
      "source": [
        "# Train model\n",
        "from transformers import BertConfig, TFBertForSequenceClassification\n",
        "\n",
        "# Load Model\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "\n",
        "#print(tensorflow.__version__)\n",
        "from transformers import BertConfig\n",
        "model_config = BertConfig.from_pretrained('bert-base-uncased')\n",
        "model_config.num_labels = 1\n",
        "\n",
        "from transformers import TFBertForSequenceClassification\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', config=model_config)\n",
        "\n",
        "loss = tf.keras.losses.MeanSquaredError\n",
        "metric = tf.keras.metrics.MeanSquaredError('mse')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=[metric])\n",
        "print(model.summary())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertForSequenceClassification: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier', 'dropout_75']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  109482240 \n",
            "_________________________________________________________________\n",
            "dropout_75 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  769       \n",
            "=================================================================\n",
            "Total params: 109,483,009\n",
            "Trainable params: 109,483,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5chqgeBZ-kF"
      },
      "source": [
        "#model.fit([train_x, train_mask], train_y, batch_size=32, epochs=2, validation_data=([test_x, test_mask], test_y), callbacks=checkpoint)\n",
        "model.fit()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}